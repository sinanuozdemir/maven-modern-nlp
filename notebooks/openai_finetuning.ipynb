{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12307e14",
   "metadata": {},
   "source": [
    "### OpenAI's guide to fine-tuning: https://platform.openai.com/docs/guides/fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaaccb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "338de565",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def test_prompt(prompt, suppress=False, model='text-davinci-003', max_tokens=256, **kwargs):\n",
    "\n",
    "    response = openai.Completion.create(\n",
    "      model=model,\n",
    "      prompt=prompt,\n",
    "      max_tokens=max_tokens,\n",
    "      **kwargs\n",
    "    )\n",
    "    if not suppress:\n",
    "        print(f'PROMPT:\\n------\\n{prompt}\\n------\\nRESPONSE\\n------\\n{prompt}{response.choices[0].text}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84474ed7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b4021a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT:\n",
      "------\n",
      "Review: This movie sucks\n",
      "Subjective: Yes\n",
      "###\n",
      "Review: This tv show was about the ocean\n",
      "Subjective: No\n",
      "###\n",
      "Review: This book had a lot of flaws\n",
      "Subjective: Yes\n",
      "###\n",
      "Review: The book was about WWII\n",
      "Subjective:\n",
      "------\n",
      "RESPONSE\n",
      "------\n",
      "Review: This movie sucks\n",
      "Subjective: Yes\n",
      "###\n",
      "Review: This tv show was about the ocean\n",
      "Subjective: No\n",
      "###\n",
      "Review: This book had a lot of flaws\n",
      "Subjective: Yes\n",
      "###\n",
      "Review: The book was about WWII\n",
      "Subjective: No\n"
     ]
    }
   ],
   "source": [
    "examples = [\n",
    "    ('Review: This movie sucks\\nSubjective: Yes'),\n",
    "    ('Review: This tv show was about the ocean\\nSubjective: No'),\n",
    "    ('Review: This book had a lot of flaws\\nSubjective: Yes'),\n",
    "    \n",
    "    ('Review: The book was about WWII\\nSubjective:'),\n",
    "]\n",
    "\n",
    "test_prompt('\\n###\\n'.join(examples))  # ### is a common few-shot separator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c990d0d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Review: This movie sucks\\nSubjective:', 'Yes'),\n",
       " ('Review: This tv show was about the ocean\\nSubjective:', 'No'),\n",
       " ('Review: This book had a lot of flaws\\nSubjective:', 'Yes')]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts = [example.split('Subjective: ')[0]+'Subjective:' for example in examples[:-1]]\n",
    "labels = [example.split('Subjective: ')[1] for example in examples[:-1]]\n",
    "\n",
    "list(zip(prompts, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c3441cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "\n",
    "# for review, label in zip(reviews, labels):\n",
    "#     # don't forget the space before the label. It's not technically required, but GPT is\n",
    "#     # used to predicing a space so it will make the training easier\n",
    "#     rows.append({\"prompt\": review, \"completion\": f' {label}'})\n",
    "\n",
    "    \n",
    "for prompt, label in zip(prompts, labels):\n",
    "    # don't forget the space before the label. It's not technically required, but GPT is\n",
    "    # used to predicing a space so it will make the training easier\n",
    "    rows.append({\"prompt\": prompt, \"completion\": f' {label}'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5ba6bc79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'prompt': 'Review: This movie sucks\\nSubjective:', 'completion': ' Yes'},\n",
       " {'prompt': 'Review: This tv show was about the ocean\\nSubjective:',\n",
       "  'completion': ' No'},\n",
       " {'prompt': 'Review: This book had a lot of flaws\\nSubjective:',\n",
       "  'completion': ' Yes'}]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e173d9",
   "metadata": {},
   "source": [
    "### More info on Fine-tuning: https://help.openai.com/en/articles/6811186-how-do-i-format-my-fine-tuning-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d805d50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('../data/openai-fine-tuning-10.jsonl', 'w') as outfile:\n",
    "    for entry in rows:\n",
    "        json.dump(entry, outfile)\n",
    "        outfile.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "88aa42e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 249/249 [00:00<00:00, 126kit/s]\n",
      "Uploaded file from ../data/openai-fine-tuning-10.jsonl: file-zdP7l4c5Bw1Iz406A5zrnuEJ\n",
      "Created fine-tune: ft-c7QutbCMSGuDOxIEDmxUy8Aq\n",
      "Streaming events until fine-tuning is complete...\n",
      "\n",
      "(Ctrl-C will interrupt the stream, but not cancel the fine-tune)\n",
      "[2023-02-13 13:27:40] Created fine-tune: ft-c7QutbCMSGuDOxIEDmxUy8Aq\n",
      "\n",
      "Stream interrupted (client disconnected).\n",
      "To resume the stream, run:\n",
      "\n",
      "  openai api fine_tunes.follow -i ft-c7QutbCMSGuDOxIEDmxUy8Aq\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!openai api fine_tunes.create -t \"../data/openai-fine-tuning-10.jsonl\" --model davinci --n_epochs 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e6a416",
   "metadata": {},
   "source": [
    "### GET READY TO WAIT IN A QUEUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1b6d6794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-02-13 13:27:40] Created fine-tune: ft-c7QutbCMSGuDOxIEDmxUy8Aq\n",
      "[2023-02-13 13:40:34] Fine-tune costs $0.01\n",
      "[2023-02-13 13:40:34] Fine-tune enqueued. Queue number: 0\n",
      "[2023-02-13 13:40:34] Fine-tune is in the queue. Queue number: 0\n",
      "[2023-02-13 13:40:35] Fine-tune started\n",
      "[2023-02-13 13:42:58] Completed epoch 1/10\n",
      "[2023-02-13 13:42:59] Completed epoch 2/10\n",
      "[2023-02-13 13:43:00] Completed epoch 3/10\n",
      "[2023-02-13 13:43:01] Completed epoch 4/10\n",
      "[2023-02-13 13:43:02] Completed epoch 5/10\n",
      "[2023-02-13 13:43:03] Completed epoch 6/10\n",
      "[2023-02-13 13:43:04] Completed epoch 7/10\n",
      "[2023-02-13 13:43:05] Completed epoch 8/10\n",
      "[2023-02-13 13:43:06] Completed epoch 9/10\n",
      "[2023-02-13 13:43:07] Completed epoch 10/10\n",
      "[2023-02-13 13:43:39] Uploaded model: davinci:ft-personal-2023-02-13-21-43-39\n",
      "[2023-02-13 13:43:40] Uploaded result file: file-Hwd2xXE7dCxU5lT9fpcbNnet\n",
      "[2023-02-13 13:43:40] Fine-tune succeeded\n",
      "\n",
      "Job complete! Status: succeeded ðŸŽ‰\n",
      "Try out your fine-tuned model:\n",
      "\n",
      "openai api completions.create -m davinci:ft-personal-2023-02-13-21-43-39 -p <YOUR_PROMPT>\n"
     ]
    }
   ],
   "source": [
    "!openai api fine_tunes.follow -i ft-c7QutbCMSGuDOxIEDmxUy8Aq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "654df566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT:\n",
      "------\n",
      "Review: The book was about WWII\n",
      "Subjective:\n",
      "------\n",
      "RESPONSE\n",
      "------\n",
      "Review: The book was about WWII\n",
      "Subjective: I really enjoyed reading this book. It was very historical and interesting.\n"
     ]
    }
   ],
   "source": [
    "# base GPT 3.5\n",
    "test_prompt(\n",
    "    'Review: The book was about WWII\\nSubjective:'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "863efd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "FINE_TUNED_MODEL = 'davinci:ft-personal-2023-02-13-21-24-55'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f41bc633",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT:\n",
      "------\n",
      "Review: The book was about WWII\n",
      "Subjective:\n",
      "------\n",
      "RESPONSE\n",
      "------\n",
      "Review: The book was about WWII\n",
      "Subjective: Yes\n"
     ]
    }
   ],
   "source": [
    "# Our fine-tuned GPT3 model\n",
    "\n",
    "# Don't forget to alter the prompt to be aligned with the fine tuning. \n",
    "#  In our case, we didn't change it\n",
    "\n",
    "# Clearly the model is wrong but this is because you want at least a hundred examples\n",
    "test_prompt(\n",
    "    'Review: The book was about WWII\\nSubjective:',\n",
    "    model=FINE_TUNED_MODEL,\n",
    "    max_tokens=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d45a5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c7a2e60",
   "metadata": {},
   "source": [
    "# PROS\n",
    "### - No need for few-shot\n",
    "### - shorter prompts (theoretically no need for \"Question: \"\n",
    "### - Don't need that many examples\n",
    "### - Saves space in the token window\n",
    "### - More aligned with what WE want from GPT, not OpenAI\n",
    "### - Optional classification metrics can be calculated given a testing set\n",
    "### - Can rely on smaller/faster/cheaper models IF YOU HAVE ENOUGH (minimum >= ~100) EXAMPLES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a69f077",
   "metadata": {},
   "source": [
    "# CONS\n",
    "### - Waiting in queue\n",
    "### - No way to get performance metrics on non simple classification tasks like translation, sumamrization, Q/A, etc\n",
    "### - Can only fine-tune language modeling (predicting next token), can't fine-tune RLHF (for now)\n",
    "### - Very little control over traditional deep learning fine-tuning parameters (like learning rate, weight decay, etc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
